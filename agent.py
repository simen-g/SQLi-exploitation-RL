import numpy as np
import env
import const
import sys
import utilities as ut
from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter

"""
agent.py is based on FMZennaro's agent on https://github.com/FMZennaro/CTF-RL/blob/master/Simulation1/agent.py
"""

class Agent():
	def __init__(self, actions, verbose, deterministic):
		self.actions = actions
		self.num_actions = len(actions)

		self.Q = {(): np.ones(self.num_actions)}

		self.verbose = verbose
		self.deterministic = deterministic
		self.set_learning_options()
		self.used_actions = []
		self.powerset = None

		self.steps = 0
		self.rewards = 0
		self.total_trials = 0
		self.total_successes = 0

	def set_learning_options(self,exploration=0.2,learningrate=0.1,discount=0.9, max_step = 100):
		self.expl = exploration
		self.lr = learningrate
		self.discount = discount
		self.max_step = max_step

	def _select_action(self):
		if (np.random.random() < self.expl and not deterministic):
			return np.random.randint(0,self.num_actions)
		else:
			return np.argmax(self.Q[self.state])

	def step(self):
		self.steps = self.steps + 1
		#print(f"Step {self.steps}:")

		if self.verbose:
			print()
			print(f"Step {self.steps}:")
			print(f"My state is: {self.state}")
			print(f"My Q row looks like this: {self.Q[self.state]}")
			print(f"My action ranking is: {np.argsort(self.Q[self.state])[::-1]}")

		action = self._select_action()
		if self.verbose:
			print("Action equal highest rank: ",action == np.argsort(self.Q[self.state])[::-1][0])


		state_resp, reward, termination, result_message = self.env.step(self.actions[action])
		self._analyze_response(action, state_resp, reward)
		self.terminated = termination
		self.used_actions.append(action)
		if self.verbose:
			print(result_message)
		return

	def run_episode(self):
		_,_,self.terminated,debug_message = self.env.reset()
		if(self.verbose):
			print(f"{debug_message}\n\n\n")

		while (not(self.terminated)) and self.steps < self.max_step:
			self.step()

		self.total_trials += 1
		if(self.terminated):
			self.total_successes += 1
		return self.terminated



	def _update_state(self, action_nr, response_interpretation):
		"""
		response interpretation is either -1 or 1
		"""
		action_nr += 1
		x = list(set(list(self.state) + [response_interpretation*action_nr]))
		x.sort()
		x = tuple(x)
		self.Q[x] = self.Q.get(x, np.ones(self.num_actions))

		self.oldstate = self.state
		self.state = x


	def _update_Q(self, action, reward):
		best_action_newstate = np.argmax(self.Q[self.state])
		self.Q[self.oldstate][action] = self.Q[self.oldstate][action] + self.lr * (reward + self.discount*self.Q[self.state][best_action_newstate] - self.Q[self.oldstate][action])


	def _analyze_response(self, action, response, reward):
		expl1 = 1 	# SOMETHING
		expl2 = 2 	# NOTHING
		flag  = 3 	#FLAG
		expl3 = 4 	#SOMETHING
		wrong1 = 0 	#NOTHING
		wrong2 = -1 #NOTHING


		#The agent recieves SOMETHING as the response
		if(response==expl1 or response == expl3 or response == flag):
			self._update_state(action, response_interpretation = 1)
		#NOTHING2
		elif(response == expl2 or response==wrong1 or response == wrong2):
			self._update_state(action, response_interpretation = -1)
		else:
			print("ILLEGAL RESPONSE")
			sys.exit()

		##Not sure if this condition is can be removed or not
		##Behaves as expected when removed
		#if(not deterministic):
		self._update_Q(action, reward)

	def reset(self,env):
		self.env = env
		self.terminated = False
		self.state = () #empty tuple
		self.oldstate = None
		self.used_actions = []

		self.steps = 0
		self.rewards = 0


if __name__ == "__main__":
	# Parse command line arguments
	parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)
	parser.add_argument("-d", "--deterministic", help="Deterministic actions", action="store_true")
	parser.add_argument("-v", "--verbose", help="Verbose", action="store_true")
	args = vars(parser.parse_args())
	verbose = args["verbose"]
	deterministic = args["deterministic"]

	a = Agent(const.actions, verbose , deterministic)
	env = env.SQLi_Environment(verbose)

	number_of_episodes = 10
	a.reset(env)
	for i in range(number_of_episodes):
		a.run_episode()
	if verbose:
		print(f"\nNumber of trials: {a.total_trials} \nNumber of successes: {a.total_successes}")
